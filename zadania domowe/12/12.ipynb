{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from collections import namedtuple"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 12 - Writing GPU Kernels\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The homework will be an extension of what we did in the lecture.\n",
    "This time, we will implement the matrix multiplication kernel using Triton.\n",
    "To simplify the problem, we will assume that the matrices are square and of the same size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def matrix_multiplication(blockIdx, blockDim, threadIdx, A, B, C):\n",
    "    \"\"\"\n",
    "    CUDA kernel for matrix multiplication C = A @ B\n",
    "    Where A and B are square matrices of size n x n\n",
    "\n",
    "    Your task is to implement the matrix multiplication kernel\n",
    "    (see https://www.mathsisfun.com/algebra/matrix-multiplying.html,\n",
    "    chapter \"Multiplying a Matrix by Another Matrix\")\n",
    "\n",
    "    Note that right now the blocks and threads are two-dimensional, so that we can\n",
    "    process 2D data (matrices). The x-dimension indexes the rows of the\n",
    "    output matrix C, and the y-dimension indexes the columns of C.\n",
    "    This allows the kernel to execute in parallel computation of\n",
    "    ANY output element of C, with the proper indexing of a 2D matrix.\n",
    "\n",
    "    This does not have to be the most efficient implementation,\n",
    "    but it should be correct and demonstrate your understanding of\n",
    "    the problem.\n",
    "    \n",
    "    Note: Be careful with the boundary conditions for the threads.\n",
    "    We do not want to access elements outside the matrix\n",
    "    (\"step\" into the undefined memory space).\n",
    "\n",
    "    :param blockIdx: Block index in the grid\n",
    "    :param blockDim: Block dimension\n",
    "    :param threadIdx: Thread index in the block\n",
    "    :param A: First input matrix\n",
    "    :param B: Second input matrix\n",
    "    :param C: Output matrix\n",
    "    \"\"\"\n",
    "    # Calculate row and column for this thread\n",
    "    row = blockIdx.x * blockDim.x + threadIdx.x\n",
    "    col = blockIdx.y * blockDim.y + threadIdx.y\n",
    "    \n",
    "    # <your_code_here>\n",
    "    n = len(A)\n",
    "    \n",
    "    # Check boundary conditions to prevent accessing out-of-bounds memory\n",
    "    if row < n and col < n:\n",
    "        sum_value = 0\n",
    "        for k in range(n):\n",
    "            sum_value += A[row][k] * B[k][col]\n",
    "        C[row][col] = sum_value\n",
    "    # </your_code_here>\n",
    "\n",
    "\n",
    "def run_kernel(*kernel_args):\n",
    "    NUM_THREADS = 64\n",
    "\n",
    "    # Define the dimensions of the grid and block\n",
    "    DimGrid = namedtuple(\"block_dimensions\", [\"x\", \"y\"])\n",
    "    DimBlock = namedtuple(\"thread_dimensions\", [\"x\", \"y\"])\n",
    "    CurrentBlock = namedtuple(\"current_block\", [\"x\", \"y\"])\n",
    "    CurrentThread = namedtuple(\"current_thread\", [\"x\", \"y\"])\n",
    "\n",
    "    # DimGrid is an object that holds the number of blocks in the x and y dimensions\n",
    "    dim_grid = DimGrid(\n",
    "        np.ceil(n / NUM_THREADS).astype(np.int32),\n",
    "        np.ceil(n / NUM_THREADS).astype(np.int32),\n",
    "    )\n",
    "    # DimBlock is an object that holds the number of threads in the x and y dimensions\n",
    "    dim_block = DimBlock(NUM_THREADS, NUM_THREADS)\n",
    "\n",
    "    for block_i in range(dim_grid.x):\n",
    "        for block_j in range(dim_grid.y):\n",
    "            for thread_i in range(dim_block.x):\n",
    "                for thread_j in range(dim_block.y):\n",
    "                    matrix_multiplication(\n",
    "                        CurrentBlock(block_i, block_j),\n",
    "                        dim_block,\n",
    "                        CurrentThread(thread_i, thread_j),\n",
    "                        *kernel_args,\n",
    "                    )\n",
    "\n",
    "\n",
    "n = 16\n",
    "# define matrix A\n",
    "A = np.random.randn(n, n)\n",
    "# define matrix B\n",
    "B = np.random.randn(n, n)\n",
    "# the result of A*B is C\n",
    "C = np.empty((n, n))\n",
    "\n",
    "run_kernel(A, B, C)\n",
    "\n",
    "assert np.allclose(C, A @ B)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65.27918243408203\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[41], line 118\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;66;03m# print difference\u001b[39;00m\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28mprint\u001b[39m(torch\u001b[38;5;241m.\u001b[39mnorm(C \u001b[38;5;241m-\u001b[39m A \u001b[38;5;241m@\u001b[39m B)\u001b[38;5;241m.\u001b[39mitem())\n\u001b[0;32m--> 118\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mallclose(C, A \u001b[38;5;241m@\u001b[39m B, atol\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-2\u001b[39m)\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"TRITON_INTERPRET\"] = \"1\"\n",
    "\n",
    "import triton\n",
    "import triton.language as tl\n",
    "import torch\n",
    "\n",
    "@triton.jit\n",
    "def matrix_multiplication_kernel(\n",
    "    A_ptr, B_ptr, C_ptr,\n",
    "    M, N, K,\n",
    "    BLOCK_SIZE: tl.constexpr,\n",
    "):\n",
    "    \"\"\"\n",
    "    Matrix multiplication using 2D program IDs\n",
    "    \n",
    "    Notes:\n",
    "    \n",
    "    1) This time we will use the 2D program IDs to index the matrix elements.\n",
    "    i.e.\n",
    "    ```\n",
    "    pid_row = tl.program_id(0)\n",
    "    pid_col = tl.program_id(1)\n",
    "    ```\n",
    "    \n",
    "    2) Most likely you will use an \"accumulator\" to store the result of the matrix multiplication.\n",
    "    I recommend to initialize it with zeros:\n",
    "    ```\n",
    "    acc = tl.full((BLOCK_SIZE, BLOCK_SIZE), 0.0, dtype=tl.float32)\n",
    "    ```\n",
    "    \n",
    "    This task may be potentially challenging to some of you. \n",
    "    If you have any questions, please ask in the Discord.\n",
    "    Also feel free to converse with AI to get help and seek clarification.\n",
    "    \n",
    "    \n",
    "    :param A_ptr: Pointer to matrix A (shape: M x K)\n",
    "    :param B_ptr: Pointer to matrix B (shape: K x N)\n",
    "    :param C_ptr: Pointer to output matrix C (shape: M x N)\n",
    "    :param M: Number of rows in A and C\n",
    "    :param N: Number of columns in B and C\n",
    "    :param K: Number of columns in A and rows in B\n",
    "    :param BLOCK_SIZE: Tile size for all dimensions\n",
    "    \"\"\"\n",
    "    # <your_code_here>\n",
    "    # Suggested approach:\n",
    "    # 1) Get 2D program ID\n",
    "    # 2) Compute row/column offsets\n",
    "    # 3) Create masks (x and y dimensions)\n",
    "    # 4) Initialize accumulator\n",
    "    # 5) Loop over K dimension\n",
    "    # 6) Load A and B tiles\n",
    "    # 7) Perform matrix multiplication\n",
    "    # 8) Store result\n",
    "\n",
    "    row_start = tl.program_id(0) * BLOCK_SIZE\n",
    "    col_start = tl.program_id(1) * BLOCK_SIZE \n",
    "    #print(row_start, col_start)\n",
    "    offset_row = row_start + tl.arange(0, BLOCK_SIZE)\n",
    "    offset_col = col_start + tl.arange(0, BLOCK_SIZE)\n",
    "\n",
    "    # Create masks to handle out-of-bounds access\n",
    "    mask_row = offset_row < M\n",
    "    mask_col = offset_col < N\n",
    "    \n",
    "    # Initialize accumulator with zeros\n",
    "    acc = tl.full((1, 1), 0.0, dtype=tl.float32)\n",
    "    \n",
    "    # Loop over K dimension\n",
    "    \n",
    "    mask_elements_in_row = offset_row < K\n",
    "    mask_elements_in_col = offset_col < K\n",
    "    for k in range(0, BLOCK_SIZE):\n",
    "        \n",
    "        # wyłuskałem kolejne wektory do wymnożenia dla danej komórki macierzy wynikowej\n",
    "        # ale zupełnie nie wiem co mam dalej z tym zrobić\n",
    "        A_block = tl.load(A_ptr + k*K + offset_row, mask=mask_elements_in_row & (k<M))\n",
    "        B_block = tl.load(B_ptr + offset_col*N + k, mask=mask_elements_in_col & (k<N))\n",
    "\n",
    "        # wyrzuca mi error, nie wiem co mam zrobić z tym, że dot chce macierzy 2d i nie umie wymnożyć 2 wektorów\n",
    "        #c = tl.dot(A_block, B_block)\n",
    "\n",
    "\n",
    "\n",
    "    # tu byłby store gdybym miał siłe jeszcze w tym grzebać\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # zupełnie serio, nie kumam jak ten triton ma działać\n",
    "    # niby równolegle, ale trzeba wyłuskiwać wektory?\n",
    "    # nie jestem pewien czy dobrze zrozumiałem zadanie, albo jak ma być rozwiązane  <------\n",
    "    # pachnie trochę cublasem i takim wymyślnym myśleniem, \n",
    "    # że programista to powinien liczyć sobie 17 osiowe \n",
    "    # przestrzenie w pamięci i znać offsety do każdej z komórek\n",
    "    # w tej cudownej przestrzeni, \n",
    "\n",
    "    # wiem, że robie mnożenie macierzy, ale to nie zmienia faktu,\n",
    "    # że to się słabo skaluje w wyższe wymiary (przynajmniej tak się wydaje)\n",
    "\n",
    "    # w sensie, serio, to chyba nie tędy droga\n",
    "    # żeby ktoś siedział i modlił się żeby się nie pomylić\n",
    "    # co ma pomnożyć przez co \n",
    "\n",
    "    # nie spodobał mi się ten framework, 2/10\n",
    "\n",
    "    # czy mógłbyś proszę wytłumaczyć mi, jak to miało zostać zrobione?                      <------\n",
    "    # czytałem przykład tritonowy jak policzyć iloczyn macierzy\n",
    "    # https://triton-lang.org/main/getting-started/tutorials/03-matrix-multiplication.html#sphx-glr-getting-started-tutorials-03-matrix-multiplication-py\n",
    "    # ale szczerze? \n",
    "    # jest przejebanie przekąplikowany xD \n",
    "    # czytałem go tak z 5 razy i nie skumałem co oni dokładnie \n",
    "    # tam robią\n",
    "\n",
    "    # </your_code_here>\n",
    "    \n",
    "# Test the implementation\n",
    "n = 16\n",
    "A = torch.randn((n, n), device='cuda')\n",
    "B = torch.randn((n, n), device='cuda')\n",
    "\n",
    "M, K = A.shape\n",
    "K, N = B.shape\n",
    "\n",
    "# Allocate output\n",
    "C = torch.empty((M, N), device=A.device, dtype=A.dtype)\n",
    "\n",
    "# Define block size\n",
    "BLOCK_SIZE = 64\n",
    "\n",
    "# Launch kernel\n",
    "grid = lambda meta: (\n",
    "    triton.cdiv(M, meta['BLOCK_SIZE']),\n",
    "    triton.cdiv(N, meta['BLOCK_SIZE'])\n",
    ")\n",
    "\n",
    "matrix_multiplication_kernel[grid](\n",
    "    A, B, C,\n",
    "    M, N, K,\n",
    "    BLOCK_SIZE\n",
    ")\n",
    "\n",
    "# print difference\n",
    "print(torch.norm(C - A @ B).item())\n",
    "\n",
    "\n",
    "\n",
    "assert torch.allclose(C, A @ B, atol=1e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
